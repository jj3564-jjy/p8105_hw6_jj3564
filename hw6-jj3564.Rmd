---
title: "hw6"
author: "Kate"
date: "2025-12-03"
output:  github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(broom)
library(modelr)
library(p8105.datasets)
library(forcats)

set.seed(1)
theme_set(theme_minimal(base_size = 14))
```

## Problem 1

```{r, warning = FALSE}
# Import homicide data from Washington Post GitHub
homicide_raw <- read_csv(
  "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
)

# indicator identification and split data
homicide_clean <- homicide_raw %>%
  mutate(
    city_state = str_c(city, ", ", state),
    solved = disposition == "Closed by arrest"
  )%>%
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", 
                      "Kansas City, MO", "Tulsa, AL")
  ) %>%
  filter(victim_race %in% c("White", "Black")) %>%
  mutate(
    victim_age = as.numeric(victim_age),
    victim_sex = factor(victim_sex),
    victim_race = factor(victim_race)
  )

```

### Logistic Regression for one city
```{r}
logistic_df <- homicide_clean %>%
  filter(city_state == "Baltimore, MD")

logistic_fit <- glm(
  solved ~ victim_age + victim_sex + victim_race,
  data = logistic_df,
  family = binomial()
)

logistic_OR <- logistic_fit %>%
  tidy(conf.int = TRUE, exponentiate = TRUE) %>%
  filter(term == "victim_sexMale") %>%
  select(term, estimate, conf.low, conf.high)

logistic_OR
```

### Logistic Regression for Each City 
```{r}
city_ORs <- homicide_clean %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(
    fit = map(
      data,
      ~ glm(solved ~ victim_age + victim_sex + victim_race,
            data = .x,
            family = binomial())
    ),
    tidied = map(
      fit,
      ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
    )
  ) %>%
  unnest(tidied) %>%
  filter(term == "victim_sexMale") %>%
  select(city_state, estimate, conf.low, conf.high)

city_ORs
```
### plot for each city
```{r}


city_ORs_plotdata <- city_ORs 

ggplot(city_ORs_plotdata,
aes(x = fct_reorder(city_state,estimate,.desc = TRUE), y = estimate,
ymin = conf.low, ymax = conf.high)) +
geom_pointrange() +
geom_hline(yintercept = 1, linetype = "dashed") +
coord_flip() +
labs(
x = "City",
y = "Odds ratio (Male vs Female victims)",
title = "Estimated odds ratios of homicide case being solved,\nby victim sex and city",
subtitle = "Points = OR estimates; bars = 95% confidence intervals; dashed line = OR = 1"
) +
theme(
    axis.text.y = element_text(size = 6)
)
```
####comment Most estimated odds ratios cluster around 1, and many confidence intervals are wide and cross the reference line, suggesting that in many cities there is no strong evidence of a difference in clearance rates between male and female victims.    A smaller subset of cities shows ORs noticeably above 1, indicating higher odds of case resolution for male victims, although again several of these estimates have considerable uncertainty due to limited sample size.

### problem 2

```{r}
data("weather_df")


# 1. Clean data


weather_clean <- weather_df %>%
  drop_na(tmax, tmin, prcp)  


# 2. Create 5000 bootstrap resamples


weather_bootstrap <- weather_clean %>%
  bootstrap(n = 5000, id = "bootstrap_id")


# 3. Fit models on each bootstrap sample


bootstrap_results <- weather_bootstrap %>%
  mutate(
    fit_model   = map(strap, ~ lm(tmax ~ tmin + prcp, data = .x)),
    model_glance = map(fit_model, glance),
    model_tidy   = map(fit_model, tidy)
  )


# 4. Extract R-squared values


bootstrap_r2 <- bootstrap_results %>%
  unnest(model_glance) %>%
  select(bootstrap_id, r.squared)


# 5. Extract coefficients and compute beta1/beta2 ratio


bootstrap_coef_ratio <- bootstrap_results %>%
  unnest(model_tidy) %>%
  filter(term %in% c("tmin", "prcp")) %>%
  select(bootstrap_id, term, estimate) %>%
  pivot_wider(names_from = term, values_from = estimate) %>%
  mutate(coef_ratio_tmin_prcp = tmin / prcp) %>%
  select(bootstrap_id, coef_ratio_tmin_prcp)


# 6. Merge the results


bootstrap_summary <- bootstrap_r2 %>%
  inner_join(bootstrap_coef_ratio, by = "bootstrap_id")

bootstrap_summary
```
```{r}
# R-squared distribution
ggplot(bootstrap_summary, aes(x = r.squared)) +
  geom_histogram(bins = 40, fill = "#0057A8", alpha = 0.7) +
  labs(
    title = "Bootstrap distribution of R-squared",
    x = expression(hat(r)^2),
    y = "Count"
  ) +
  theme_minimal()

# beta1 / beta2 distribution
ggplot(bootstrap_summary, aes(x = coef_ratio_tmin_prcp)) +
  geom_histogram(bins = 40, fill = "#E53935", alpha = 0.7) +
  labs(
    title = "Bootstrap distribution of beta1 / beta2",
    x = expression(hat(beta)[1] / hat(beta)[2]),
    y = "Count"
  ) +
  theme_minimal()

```
comments:
The bootstrap distribution of r squared shows that the model fits very consistently well, with minimal sampling variability. Across the 5000 bootstrap samples, the model explains roughly 94.2% of the variance in tmax, and this estimate remains extremely stable even when the model is repeatedly refit on resampled datasets. The tight, symmetric distribution indicates that the explanatory power of the model is highly robust and does not depend strongly on any particular subset of observations.
In contrast, the bootstrap distribution of the coefficient ratio ùõΩ1/Œ≤2
 is far less stable. The ratio is consistently negative, reflecting that the two coefficients almost always have opposite signs, but the distribution is noticeably wide and skewed. This suggests substantial variability in the relative strength of the two predictors. The large spread in the ratio is likely driven by the fact that 
Œ≤2(the precipitation coefficient) can be small in magnitude in many bootstrap samples, which produces instability when taking the ratio. Overall, estimating the comparative influence of tmin and prcp is much less stable than estimating the model‚Äôs overall goodness-of-fit.
```{r}
# 95% bootstrap intervals
r2_ci <- bootstrap_summary %>%
  summarise(
    q2.5  = quantile(r.squared, 0.025),
    q97.5 = quantile(r.squared, 0.975)
  )

ratio_ci <- bootstrap_summary %>%
  summarise(
    q2.5  = quantile(coef_ratio_tmin_prcp, 0.025),
    q97.5 = quantile(coef_ratio_tmin_prcp, 0.975)
  )

r2_ci
ratio_ci
```


###problem3
```{r}
#data cleaning
birth_raw <- read_csv("./data/birthweight.csv")

birth_df <- birth_raw %>%
  mutate(
    babysex = factor(babysex, levels = c(1, 2),
                     labels = c("male", "female")),
    frace   = factor(frace),
    mrace   = factor(mrace),
    malform = factor(malform, levels = c(0, 1),
                     labels = c("absent", "present"))
  ) %>% 
  drop_na()
```
```{r}
mod_main2 <- lm(
  bwt ~ bhead + blength * babysex + gaweeks +
    ppbmi + wtgain + smoken,
  data = birth_df
)

summary(mod_main2)
```

```{r}
# model choice
mod_main2 <- lm(
  bwt ~ bhead + blength * babysex + gaweeks +
    ppbmi + wtgain + smoken,
  data = birth_df
)

summary(mod_main2)

```
I choose model for these reasons
a.Maternal characteristics that influence intrauterine growth‚Äîsuch as pre-pregnancy BMI (ppbmi), pregnancy weight gain (wtgain), smoking during pregnancy (smoken), and gestational age (gaweeks)‚Äîare included because they directly affect fetal development and nutritional environment.
b.Measures of fetal size at birth, including head circumference (bhead) and length (blength), capture the newborn‚Äôs physical growth. 
3.In addition,I incorporate an interaction between birth length and sex (babysex * blength) to allow for the possibility that sex-specific differences in birthweight are expressed partially through differences in skeletal growth.

```{r}

birth_aug2 <- birth_df %>%
  add_predictions(mod_main2) %>%
  add_residuals(mod_main2)

birth_aug2 %>%
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.4) +
  geom_hline(yintercept = 0, linetype = 2) +
  labs(
    title = "Residuals vs fitted values: Main Model ",
    x = "Fitted birthweight",
    y = "Residuals"
  )
```
from residuals, we can easily they the distribution center is around 0 and it is looked a random one.and to get more information, we can use more plots in R
```{r}
plot(mod_main2)
```
from qq and residuls graph, we cam generally support normal distribution for unbiased prediction. But two points to be careful ,from QQ we can see some ourliners which may cause problem and also for variance, it has a probablity to consider about heteroscedasticity
```{r}
# replicate camparision model
mod1 <- lm(bwt ~ blength + gaweeks, data = birth_df)

mod2 <- lm(
  bwt ~ bhead * blength * babysex,
  data = birth_df
)
```

```{r}
cv_df <- crossv_mc(birth_df, n = 100)

cv_results2 <- cv_df %>%
  mutate(
    train = map(train, as_tibble),
    test  = map(test, as_tibble),

    # fit all 3 models
    fit_main2 = map(train, ~ lm(
      bwt ~ bhead + blength * babysex + gaweeks +
        ppbmi + wtgain + smoken,
      data = .x
    )),
    fit_mod1 = map(train, ~ lm(
      bwt ~ blength + gaweeks,
      data = .x
    )),
    fit_mod2 = map(train, ~ lm(
      bwt ~ bhead * blength * babysex,
      data = .x
    )),

    # RMSE computations
    rmse_main2 = map2_dbl(fit_main2, test, ~ {
      pred <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    }),
    rmse_mod1 = map2_dbl(fit_mod1, test, ~ {
      pred <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    }),
    rmse_mod2 = map2_dbl(fit_mod2, test, ~ {
      pred <- predict(.x, newdata = .y)
      sqrt(mean((.y$bwt - pred)^2))
    })
  )


cv_long2 <- cv_results2 %>%
  select(rmse_main2, rmse_mod1, rmse_mod2) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse"
  ) %>%
  mutate(
    model = recode(
      model,
      rmse_main2 = "Main Model 2.0",
      rmse_mod1  = "Model 1",
      rmse_mod2  = "Model 2"
    )
  )

cv_long2 %>%
  group_by(model) %>%
  summarise(
    mean_rmse = mean(rmse),
    sd_rmse   = sd(rmse),
    .groups = "drop"
  )
```
The cross-validated RMSE results indicate that Main Model 2.0 performs the best overall. It has the lowest mean RMSE (‚âà283 grams) and the smallest standard deviation, suggesting that it not only predicts birthweight more accurately but also produces stable predictions across the 100 random train‚Äìtest splits.yeah!
```{r}
cv_long2 %>%
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin(alpha = 0.6) +
  geom_boxplot(width = 0.1, outlier.size = 0.8, alpha = 0.8) +
  labs(
    title = "RMSE distribution by model (Violin + Boxplot)",
    x = NULL,
    y = "RMSE (test set)"
  ) +
  coord_flip() +
  theme_minimal() +
  theme(legend.position = "none")
```
In this plot, Main Model 2.0 shows the lowest and most concentrated RMSE distribution

Model 2 has a slightly higher and somewhat broader distribution, showing moderately worse accuracy and stability. Model 1, by contrast, has the widest and most right-shifted violin, with noticeably higher RMSE values and larger spread. This indicates substantial information loss when only length and gestational age are used as predictors.